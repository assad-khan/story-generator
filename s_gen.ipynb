{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "XFkXHNkTnVwm",
        "outputId": "3411705e-c55b-4f74-bed5-bcaf8367baab"
      },
      "outputs": [],
      "source": [
        "!pip install crewai TTS diffusers crewai_tools streamlit pyngrok moviepy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!ngrok authtoken give_your_token_here"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "avpf4IlpmycV",
        "outputId": "68b197da-9145-416f-9fe0-e1acc0581a98"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Writing app.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile app.py\n",
        "import os\n",
        "import torch\n",
        "import random\n",
        "import json\n",
        "import time\n",
        "from pathlib import Path\n",
        "from TTS.api import TTS\n",
        "from crewai import Agent, Task, Crew, Process, LLM\n",
        "from crewai.tools import tool\n",
        "# from diffusers import StableDiffusionPipeline\n",
        "from diffusers import AutoPipelineForText2Image\n",
        "import streamlit as st\n",
        "from moviepy import AudioFileClip, ImageSequenceClip, concatenate_videoclips\n",
        "\n",
        "\n",
        "# Create necessary directories\n",
        "os.makedirs(\"output/images\", exist_ok=True)\n",
        "os.makedirs(\"output/audio\", exist_ok=True)\n",
        "\n",
        "api_key = 'Give API key here'\n",
        "# os.environ['OPENAI_API_KEY'] = api_key\n",
        "\n",
        "# LLM Setup\n",
        "# llm = LLM(model=\"gpt-4o-mini\")\n",
        "llm = LLM(model=\"gemini/gemini-1.5-flash\", api_key=api_key)\n",
        "# llm = LLM(model=\"ollama/llama3.2\", base_url=\"http://localhost:11434\")\n",
        "\n",
        "# Setup device\n",
        "# If using google colab use this\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "# If using local system use this\n",
        "# device = \"mps\"\n",
        "\n",
        "# Cache the TTS model initialization\n",
        "@st.cache_resource\n",
        "def load_tts_model():\n",
        "    # st.write(\"Loading TTS model...\")\n",
        "    # tts = TTS(\"tts_models/multilingual/multi-dataset/xtts_v2\").to(device)\n",
        "    tts = TTS(model_name=\"tts_models/en/ljspeech/tacotron2-DDC\", progress_bar=True).to(device)\n",
        "    # st.write(\"TTS model loaded successfully!\")\n",
        "    return tts\n",
        "\n",
        "\n",
        "@st.cache_resource\n",
        "def load_sd_pipeline():\n",
        "    pipe = AutoPipelineForText2Image.from_pretrained(\"stabilityai/sdxl-turbo\", torch_dtype=torch.float16, variant=\"fp16\")\n",
        "    pipe.to(device)\n",
        "    return pipe\n",
        "\n",
        "# Load models (cached)\n",
        "tts = load_tts_model()\n",
        "# Load SDXL pipeline and ControlNet\n",
        "pipe = load_sd_pipeline()\n",
        "\n",
        "# Update the image generation task\n",
        "@tool(\"Generate 3D Image\")\n",
        "def generate_3d_image_tool(scene_text: str, output_path: str) -> str:\n",
        "    \"\"\"Generate a realistc 3D Cartoon animation image based on the scene text.\"\"\"\n",
        "    image = pipe(prompt= scene_text, num_inference_steps=1, guidance_scale=0.0).images[0]\n",
        "    image.save(output_path)\n",
        "    return f\"Image saved at {output_path}\"\n",
        "\n",
        "\n",
        "# Streamlit App\n",
        "st.title(\"Children's Story Generator\")\n",
        "st.markdown(\"Welcome to the Children's Story Generator! This app will help you create engaging stories with images, audio, and video.\")\n",
        "\n",
        "# Initialize Session State\n",
        "if \"all_scenes_list\" not in st.session_state:\n",
        "    st.session_state.all_scenes_list = []\n",
        "if \"scene_images\" not in st.session_state:\n",
        "    st.session_state.scene_images = []\n",
        "if \"scene_audios\" not in st.session_state:\n",
        "    st.session_state.scene_audios = []\n",
        "\n",
        "# Custom CSS for button color\n",
        "st.markdown(\n",
        "    \"\"\"\n",
        "    <style>\n",
        "    .stButton button {\n",
        "        background-color: #4CAF50; /* Green */\n",
        "        color: white;\n",
        "        font-weight: bold;\n",
        "        border-radius: 5px;\n",
        "        padding: 10px 20px;\n",
        "        border: none;\n",
        "    }\n",
        "    .stButton button:hover {\n",
        "        background-color: #45a049; /* Darker green */\n",
        "        color: white;\n",
        "    }\n",
        "    </style>\n",
        "    \"\"\",\n",
        "    unsafe_allow_html=True,\n",
        ")\n",
        "\n",
        "# Initialize session state variables\n",
        "if \"num_scenes\" not in st.session_state:\n",
        "    st.session_state.num_scenes = random.randint(7, 10)\n",
        "\n",
        "if \"story_length\" not in st.session_state:\n",
        "    st.session_state.story_length = random.randint(300, 500)\n",
        "\n",
        "# Sidebar for user inputs\n",
        "with st.sidebar:\n",
        "    # Required Inputs\n",
        "    theme = st.text_input(\"üåü Theme (Required)\", \"Learning to Share\")\n",
        "    reading_level = st.selectbox(\"üìñ Reading Level (Required)\", [\"Developing Readers\", \"Before They Can Read\", \"Starting to Read\", \"Confident Readers\"])\n",
        "    moral = st.text_input(\"üí° Moral Lesson (Required)\", \"Sharing brings happiness to everyone.\")\n",
        "\n",
        "    # Advanced Settings\n",
        "    with st.expander(\"‚öôÔ∏è Advanced Settings (Optional)\"):\n",
        "        main_character = st.text_input(\"üé≠ Main Character (Optional)\", \"\")\n",
        "        num_scenes = st.number_input(\"üé¨ Number of Scenes (Optional, Default: 7-10)\", min_value=1, max_value=10, value=st.session_state.num_scenes)\n",
        "        story_length = st.number_input(\"‚úçÔ∏è Story Length (characters) (Optional, Default: 300-500)\", min_value=50, max_value=1000, value=st.session_state.story_length )\n",
        "\n",
        "\n",
        "@tool(\"Generate Audio\")\n",
        "def generate_audio(scene_text: str, output_path: str) -> str:\n",
        "    \"\"\"Convert scene text to speech and save as an audio file.\"\"\"\n",
        "    if not output_path.startswith('output/audio/'):\n",
        "        output_path = os.path.join('output/audio/', os.path.basename(output_path))\n",
        "    # sample_audio_path = 'sample1.mp3'\n",
        "    # tts.tts_to_file(text=scene_text, speaker_wav=sample_audio_path, language=\"en\", file_path=output_path)\n",
        "    tts.tts_to_file(text=scene_text, file_path=output_path)\n",
        "    return f\"Audio saved at {output_path}\"\n",
        "\n",
        "# Agents\n",
        "story_generator = Agent(\n",
        "    role=\"Story Creator\",\n",
        "    goal=\"Create an engaging children's story with structured scenes.\",\n",
        "    backstory=\"A master storyteller weaving fun and educational narratives.\",\n",
        "    verbose=True,\n",
        "    llm=llm\n",
        ")\n",
        "\n",
        "scene_editor = Agent(\n",
        "    role=\"Story Editor\",\n",
        "    goal=\"Break the story into structured scenes.\",\n",
        "    backstory=\"Ensures smooth transitions and readability.\",\n",
        "    verbose=True,\n",
        "    llm=llm\n",
        ")\n",
        "\n",
        "audio_narrator = Agent(\n",
        "    role=\"Voice Actor\",\n",
        "    goal=\"Convert text into engaging audio narration.\",\n",
        "    backstory=\"A skilled storyteller bringing words to life.\",\n",
        "    verbose=True,\n",
        "    llm=llm,\n",
        "    tools=[generate_audio]\n",
        ")\n",
        "\n",
        "\n",
        "image_generator = Agent(\n",
        "    role=\"Illustrator\",\n",
        "    goal=\"Create high-quality realistic 3D cartoon animated images for each scene with character consistency.\",\n",
        "    backstory=\"An expert AI artist specializing in 3D cartoon animated children‚Äôs book illustrations.\",\n",
        "    verbose=True,\n",
        "    llm=llm,\n",
        "    tools=[generate_3d_image_tool]\n",
        ")\n",
        "\n",
        "# Tasks\n",
        "story_task = Task(\n",
        "    description=f\"Generate a children's story on '{theme}' with the moral '{moral}'. \"\n",
        "                f\"Ensure it's suitable for '{reading_level}'. \"\n",
        "                f\"{'Use the main character: ' + main_character if main_character else 'Create an engaging main character with character consistancy.'}\",\n",
        "    expected_output=\"A structured children's story.\",\n",
        "    agent=story_generator\n",
        ")\n",
        "\n",
        "scene_task = Task(\n",
        "    description=\"Break the story into {num_scenes} structured scenes with character consistancy. In all secenes describe character. All scenes length are {story_length} characters.\",\n",
        "    expected_output=\"A JSON list of structured scenes. Each scene is string item of the list.\",\n",
        "    agent=scene_editor\n",
        ")\n",
        "\n",
        "generate_audio_task = Task(\n",
        "    description=\"Convert scene text '{scene}' into an audio narration using Generate Audio tool.\",\n",
        "    expected_output=\"A audio files saved in path {audio_path}\",\n",
        "    agent=audio_narrator,\n",
        ")\n",
        "\n",
        "\n",
        "image_task = Task(\n",
        "    description=\"Generate a realistic 3D cartoon animation image for a scene '{scene}' of the story. Ensure character consistency. \"\n",
        "                \"For a scene, construct a valid image prompt and call the 'Generate 3D Image' tool with: scene_text as \"\n",
        "                \"a STRING describing the image prompt and output_path as a STRING that is {output_path}.\",\n",
        "    expected_output=\"A realistic 3D cartoon animation image saved in path 'output/images/' with name\",\n",
        "    agent=image_generator\n",
        ")\n",
        "\n",
        "# Button to generate story\n",
        "with st.sidebar:\n",
        "    generate_clicked = st.button(\"Generate Story\", key=\"generate_story_button\")\n",
        "\n",
        "if generate_clicked:\n",
        "    if not theme or not moral:\n",
        "        st.error(\"Theme and Moral Lesson are required.\")\n",
        "        st.stop()\n",
        "\n",
        "    with st.spinner(\"Generating story...\"):\n",
        "        crew = Crew(agents=[story_generator, scene_editor], tasks=[story_task, scene_task], process=Process.sequential)\n",
        "        result = crew.kickoff(inputs={\"theme\": theme, \"reading_level\": reading_level, \"moral\": moral, \"num_scenes\": num_scenes, \"story_length\": story_length})\n",
        "        all_scenes = json.loads(scene_task.output.raw.replace(\"```json\\n\", \"\").replace(\"\\n```\", \"\"))\n",
        "\n",
        "        st.session_state.all_scenes_list = all_scenes\n",
        "        st.session_state.scene_images = []\n",
        "        st.session_state.scene_audios = []\n",
        "\n",
        "        # Display in column\n",
        "        cols = st.columns(2)  # Initialize 2 columns\n",
        "\n",
        "        for i, scene_text in enumerate(all_scenes, start=1):\n",
        "            image_path = f\"output/images/scene_{i}.png\"\n",
        "            audio_path = f\"output/audio/scene_{i}.mp3\"\n",
        "\n",
        "            # Generate image\n",
        "            crew2 = Crew(agents=[image_generator], tasks=[image_task], process=Process.sequential)\n",
        "            crew2.kickoff(inputs={\"output_path\": image_path, \"scene\": scene_text})\n",
        "\n",
        "            # Generate audio\n",
        "            crew3 = Crew(agents=[audio_narrator], tasks=[generate_audio_task], process=Process.sequential)\n",
        "            crew3.kickoff(inputs={\"audio_path\": audio_path, \"scene\": scene_text})\n",
        "\n",
        "            # Save to session state\n",
        "            st.session_state.scene_images.append(image_path)\n",
        "            st.session_state.scene_audios.append(audio_path)\n",
        "\n",
        "            # Display in column (ensure first scene starts on the left)\n",
        "            col = cols[(i - 1) % 2]  # (i-1) ensures Scene 1 starts on the left column\n",
        "            with col:\n",
        "                st.image(image_path, use_container_width=True)\n",
        "                st.markdown(f\"**üìñ Scene {i}:** {scene_text}\")\n",
        "                st.audio(audio_path)\n",
        "                if st.button(f\"Edit Scene {i}\", key=f\"edit_button_{i}\"):  # Use unique key here\n",
        "                    st.session_state.edit_scene_index = i - 1\n",
        "                    st.rerun()\n",
        "\n",
        "            # Reset columns after every 2 scenes\n",
        "            if i % 2 == 0:\n",
        "                cols = st.columns(2)  # Create new row\n",
        "\n",
        "# Display scenes in a 2-column grid\n",
        "def display_scene_grid():\n",
        "    cols = st.columns(2)\n",
        "    for idx, (scene_text, img_path, audio_path) in enumerate(zip(\n",
        "        st.session_state.all_scenes_list,\n",
        "        st.session_state.scene_images,\n",
        "        st.session_state.scene_audios\n",
        "    )):\n",
        "        col = cols[idx % 2]\n",
        "        with col:\n",
        "            st.image(img_path, use_container_width=True)\n",
        "            st.markdown(f\"**üìñ Scene {idx + 1}:** {scene_text}\")\n",
        "            st.audio(audio_path)\n",
        "            if st.button(f\"Edit Scene {idx + 1}\", key=f\"edit_{idx}\"):\n",
        "                st.session_state.edit_scene_index = idx\n",
        "                st.rerun()\n",
        "\n",
        "def create_video(image_dir: str, audio_dir: str, output_file: str) -> str:\n",
        "    \"\"\"Stitch images and audio together into a video.\"\"\"\n",
        "    if not os.path.exists(image_dir) or not os.listdir(image_dir):\n",
        "        raise FileNotFoundError(f\"Image directory '{image_dir}' is empty or does not exist.\")\n",
        "    if not os.path.exists(audio_dir) or not os.listdir(audio_dir):\n",
        "        raise FileNotFoundError(f\"Audio directory '{audio_dir}' is empty or does not exist.\")\n",
        "\n",
        "    images = sorted([os.path.join(image_dir, f) for f in os.listdir(image_dir) if f.endswith(\".png\")])\n",
        "    audios = sorted([os.path.join(audio_dir, f) for f in os.listdir(audio_dir) if f.endswith(\".mp3\")])\n",
        "\n",
        "    if not images:\n",
        "        raise FileNotFoundError(f\"No PNG images found in directory: {image_dir}\")\n",
        "    if not audios:\n",
        "        raise FileNotFoundError(f\"No MP3 audio files found in directory: {audio_dir}\")\n",
        "\n",
        "    clips = []\n",
        "    for img, audio in zip(images, audios):\n",
        "        audio_clip = AudioFileClip(audio)\n",
        "        img_clip = ImageSequenceClip([img], durations=[audio_clip.duration])\n",
        "        img_clip = img_clip.set_audio(audio_clip)\n",
        "        clips.append(img_clip)\n",
        "\n",
        "    # Use the standalone concatenate_videoclips function\n",
        "    final_video = concatenate_videoclips(clips)\n",
        "    final_video.write_videofile(output_file, codec=\"libx264\", fps=24)\n",
        "    return f\"Video saved at {output_file}\"\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Function to trigger video creation after all scenes are generated\n",
        "def generate_video_button():\n",
        "    if len(st.session_state.scene_images) > 0 and len(st.session_state.scene_audios) > 0:\n",
        "        # Only show the button once all scenes are generated\n",
        "        if st.button(\"Generate Video\", key=\"generate_video_button\"):\n",
        "            with st.spinner(\"Creating video...\"):\n",
        "                try:\n",
        "                    # Call the create_video function\n",
        "                    video_output = \"output/story_video.mp4\"\n",
        "                    create_video(\"output/images\", \"output/audio\", video_output)\n",
        "                    st.success(f\"Video created successfully!\")\n",
        "                    st.video(video_output)\n",
        "                except Exception as e:\n",
        "                    st.error(f\"Error generating video: {e}\")\n",
        "\n",
        "# Show the scenes in grid layout\n",
        "if st.session_state.scene_images and not generate_clicked:\n",
        "    display_scene_grid()\n",
        "\n",
        "# If all scenes are generated, show the video generation button at the end\n",
        "if len(st.session_state.scene_images) == len(st.session_state.all_scenes_list):\n",
        "    generate_video_button()\n",
        "\n",
        "# Edit Popup\n",
        "if \"edit_scene_index\" in st.session_state:\n",
        "    idx = st.session_state.edit_scene_index\n",
        "    scene_text = st.session_state.all_scenes_list[idx]\n",
        "    image_path = st.session_state.scene_images[idx]\n",
        "    audio_path = st.session_state.scene_audios[idx]\n",
        "\n",
        "    with st.expander(f\"‚úèÔ∏è Edit Scene {idx + 1}\", expanded=True):\n",
        "        st.image(image_path, use_container_width=True)\n",
        "        new_text = st.text_area(\"Edit Scene Text\", scene_text, height=150)\n",
        "\n",
        "        if st.button(\"Save Changes\", key=f\"save_{idx}\"):\n",
        "            if new_text:\n",
        "                with st.spinner(\"Regenerating...\"):\n",
        "                    crew2 = Crew(agents=[image_generator], tasks=[image_task], process=Process.sequential)\n",
        "                    crew2.kickoff(inputs={\"output_path\": image_path, \"scene\": new_text})\n",
        "\n",
        "                    crew3 = Crew(agents=[audio_narrator], tasks=[generate_audio_task], process=Process.sequential)\n",
        "                    crew3.kickoff(inputs={\"audio_path\": audio_path, \"scene\": new_text})\n",
        "\n",
        "                    st.session_state.all_scenes_list[idx] = new_text\n",
        "                    st.success(\"Scene updated successfully!\")\n",
        "                    del st.session_state.edit_scene_index\n",
        "                    st.rerun()\n",
        "\n",
        "        if st.button(\"Close\", key=f\"close_{idx}\"):\n",
        "            del st.session_state.edit_scene_index\n",
        "            st.rerun()\n",
        "\n",
        "st.markdown(\"---\")\n",
        "st.markdown(\"Created with AI ‚ú®\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "from pyngrok import ngrok\n",
        "\n",
        "# Kill any existing ngrok tunnels (optional)\n",
        "ngrok.kill()\n",
        "\n",
        "# Start a new ngrok tunnel for Streamlit\n",
        "public_url = ngrok.connect(8501)  # Streamlit runs on port 8501 by defaultr\n",
        "print(\"Public URL:\", public_url)\n",
        "\n",
        "# Run the Streamlit app\n",
        "!streamlit run app.py --server.port 8501"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
